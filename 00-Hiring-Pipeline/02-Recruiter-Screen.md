# Recruiter Screen (Alignment + leverage)

The recruiter screen is not “small talk.” It’s a gating conversation where the recruiter decides whether you are:

- a fit for the role + level _as written_,
- credible and coherent (communication + career story),
- logistically viable (timeline, location/remote, visa constraints),
- worth spending expensive interviewer time on.

Your goal is to **make it easy for them to move you forward**.

---

## What recruiters optimize for

Recruiters are optimizing for **throughput and risk reduction**:

- **Speed + clarity:** can they summarize you in 2–3 bullets to a hiring manager?
- **Mismatch detection:** role/level gaps, unclear scope, shaky communication, compensation/visa constraints.
- **Process predictability:** can you schedule the loop quickly? will you ghost? do you have competing deadlines?
- **Candidate quality signals:** not “buzzwords,” but evidence you can execute.

Think like a recruiter: you are giving them a clean packet of “why this person should interview.”

---

## Your objectives (leave the call with these)

1. **Role clarity:** exact title, team/domain (if known), core responsibilities.
2. **Level calibration:** what level they are targeting and why.
3. **Loop expectations:** number of rounds, types (coding/system design/behavioral/role-specific).
4. **Timeline:** expected scheduling + decision date.
5. **Constraints captured:** location, remote/hybrid policy, visa, start date.
6. **Compensation alignment:** confirm you’re not far outside their bands.

If you can only do one thing: **confirm the level**. Many disappointments later are actually mismatched level expectations early.

---

## Your 60-second pitch (template)

Use a tight structure:

1. **Who you are:** role + domain (e.g., backend + distributed systems, MLE + ranking/recs, DE + batch/streaming)
2. **Proof of impact:** 2–3 outcomes with numbers and constraints
3. **What you want next:** role + why this company archetype

Example skeleton:

> I’m a backend engineer focused on distributed systems and reliability. In my last role I owned service X at Y scale, reduced p95 latency from A to B, and cut incident volume by C% by redesigning the pipeline and rollout process. I’m looking for a role where I can own high-scale services end-to-end, do design, and be accountable for operations.

Numbers don’t need to be perfect, but they must be **directionally real**.

---

## The “evidence bullets” you should prepare

Have 6–10 bullets you can drop into conversation. Each bullet should include:

- **Problem:** what was broken / missing?
- **Action:** what did you personally do?
- **Outcome:** what moved? (latency, cost, reliability, delivery speed, revenue)
- **Constraints:** scale, time, ambiguity, cross-team dependencies

Examples:

- “Migrated monolith endpoint to async fanout + caching; p95 -40%; infra cost -15%; error rate down.”
- “Implemented canary + automated rollback; incidents due to deploys dropped from weekly to monthly.”
- “Built a feature store pipeline; reduced training/serving skew incidents; improved model iteration time from 2 weeks to 2 days.”

---

## Questions that upgrade your signal (ask 4–6)

### Role + expectations

- “What does success look like in the first 90 days?”
- “What level are you targeting and what evidence typically maps to that level?”
- “Is this role more delivery-heavy or design-heavy?”

### Interview format

- “How many coding rounds vs design vs behavioral?”
- “Is there a role-specific round (SQL/ML design/infra)?”
- “What language/environment is used for coding rounds?”

### Team + scope (if team is known)

- “Is this a product team, platform team, or infra team? What are the main systems?”
- “What’s the on-call expectation?”

### Logistics + process

- “What’s the target timeline for the loop and decision?”
- “Are there any constraints I should know about (time zones, relocation, etc.)?”

---

## Archetype differences (what to expect)

### FAANG / Big Tech

- Recruiter cares a lot about **leveling** and process: loop structure tends to be standardized.
- Expect heavy emphasis on **structured communication**; in some companies behavioral is heavily rubric-driven.

### Unicorns / high-growth startups

- More emphasis on **immediate execution**: “Can you ship?” “Can you debug prod?”
- More variability in process; may be fewer rounds but deeper dives into projects.

### Enterprise software

- More emphasis on **stakeholder management**, incremental delivery, and long-lived systems.
- Recruiter may screen for domain familiarity and collaboration.

### Automotive / industrial

- Expect early screening for **constraints and safety mindset** (validation, reliability, regulated environments).

---

## Common traps (and fixes)

- **Trap:** “I’m open to anything.”
  **Fix:** pick 1–2 lanes and explain why.
- **Trap:** listing technologies instead of outcomes.
  **Fix:** always attach impact + constraints.
- **Trap:** claiming “led” everything without crisp scope.
  **Fix:** state what you owned end-to-end vs contributed to.
- **Trap:** talking comp too early without context.
  **Fix:** confirm alignment (“are we in the same band?”) and defer details to offer stage.

---

## Cross-links

- Deep dive: [03-INTERVIEWS/01-Recruiter-Screen-Playbook.md](../03-INTERVIEWS/01-Recruiter-Screen-Playbook.md)
- Offer negotiation: [08-CAREER/04-Offer-Negotiation.md](../08-CAREER/04-Offer-Negotiation.md)

## Grounding sources

- Tech Interview Handbook (interview formats + expectations): https://www.techinterviewhandbook.org/software-engineering-interview-guide/
- Amazon “How We Hire” (process overview + loop interviews): https://www.amazon.jobs/content/en/how-we-hire/interviewing-at-amazon
- GitLab handbook (hiring philosophy + structured process): https://handbook.gitlab.com/handbook/hiring/
